{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "129c4d2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:17.530765Z",
     "start_time": "2023-06-25T11:14:17.527174Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbffbbc7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:18.256738Z",
     "start_time": "2023-06-25T11:14:17.534994Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4314de5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:18.361357Z",
     "start_time": "2023-06-25T11:14:18.259348Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/alexandradolidze/Desktop/compling/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d2477b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:18.383865Z",
     "start_time": "2023-06-25T11:14:18.366886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    0.66514\n",
       "1.0    0.33486\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a07af34c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:18.398109Z",
     "start_time": "2023-06-25T11:14:18.386534Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4a7063c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:18.405946Z",
     "start_time": "2023-06-25T11:14:18.401431Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5b50abc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:18.518927Z",
     "start_time": "2023-06-25T11:14:18.409428Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from razdel import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e05806a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:19.146689Z",
     "start_time": "2023-06-25T11:14:18.520784Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8206faf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:20.113099Z",
     "start_time": "2023-06-25T11:14:19.152762Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8577    0.9301    0.8924       959\n",
      "         1.0     0.8333    0.6936    0.7571       483\n",
      "\n",
      "    accuracy                         0.8509      1442\n",
      "   macro avg     0.8455    0.8119    0.8248      1442\n",
      "weighted avg     0.8495    0.8509    0.8471      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb667f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-23T11:34:59.045823Z",
     "start_time": "2023-06-23T11:34:59.038621Z"
    }
   },
   "source": [
    "С токенизацией razdel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "723ccb2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:24.254662Z",
     "start_time": "2023-06-25T11:14:20.115918Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(tokenizer=lambda x: [w.text for w in tokenize(x)])\n",
    "X_train_razdel = vectorizer.fit_transform(train.comment)\n",
    "X_test_razdel = vectorizer.transform(test.comment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3680d5e7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.272345Z",
     "start_time": "2023-06-25T11:14:24.257081Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8688    0.9249    0.8960       959\n",
      "         1.0     0.8290    0.7226    0.7721       483\n",
      "\n",
      "    accuracy                         0.8571      1442\n",
      "   macro avg     0.8489    0.8237    0.8340      1442\n",
      "weighted avg     0.8554    0.8571    0.8545      1442\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model_razdel = LogisticRegression()\n",
    "model_razdel.fit(X_train_razdel, y_train)\n",
    "\n",
    "y_pred_razdel = model_razdel.predict(X_test_razdel)\n",
    "\n",
    "print(classification_report(y_test, y_pred_razdel, digits = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f987004",
   "metadata": {},
   "source": [
    "Модель, обучавшаяся на данных, токенезированных razdel, дает немного (совсем немного) лучшие результаты, показывая более высокие f1-score и accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3c896c",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcd27a3",
   "metadata": {},
   "source": [
    "Преобразуйте таблицу с абсолютными частотностями в семинарской тетрадке в таблицу с tfidf значениями. (Таблица - https://i.ibb.co/r5Nc2HC/abs-bow.jpg) Формула tfidf есть в семинаре на картнике с пояснениями на английском. \n",
    "Считать нужно в питоне. Формат итоговой таблицы может быть любым, главное, чтобы был код и можно было воспроизвести вычисления. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7790511",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.278254Z",
     "start_time": "2023-06-25T11:14:25.275162Z"
    }
   },
   "outputs": [],
   "source": [
    "import re, string, math\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89f0d532",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.284325Z",
     "start_time": "2023-06-25T11:14:25.280931Z"
    }
   },
   "outputs": [],
   "source": [
    "sentences = ['я и ты', 'ты и я', 'я, я и только я', 'только не я', 'он']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e4d27688",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.292042Z",
     "start_time": "2023-06-25T11:14:25.287277Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 ['я', 'он', 'только', 'ты', 'не', 'и']\n"
     ]
    }
   ],
   "source": [
    "word_set = [re.findall(r'\\w+', sentence) for sentence in sentences]\n",
    "total_documents = len(sentences)\n",
    "unique_words = list(set(i for j in word_set for i in j))\n",
    "\n",
    "print(total_documents, unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2806067",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.301238Z",
     "start_time": "2023-06-25T11:14:25.294708Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "each_sentence = []\n",
    "idf = {}\n",
    "for sentence in word_set:\n",
    "    tf = {}\n",
    "    for token in sentence:\n",
    "        if token in tf.keys():\n",
    "            tf[token] +=1\n",
    "        else:\n",
    "            tf[token] = 1\n",
    "            if token in idf.keys():\n",
    "                idf[token] +=1\n",
    "            else:\n",
    "                idf[token] = 1\n",
    "                \n",
    "    for item in tf.keys():\n",
    "        tf[item] = tf[item]/len(sentence)\n",
    "\n",
    "    each_sentence.append(tf)\n",
    "\n",
    "for i in idf.keys():\n",
    "    idf[i] = (math.log(len(sentences)/idf[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6de217d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.307689Z",
     "start_time": "2023-06-25T11:14:25.303855Z"
    }
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(0.0, columns = unique_words, index = sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "845b6f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.319566Z",
     "start_time": "2023-06-25T11:14:25.311238Z"
    }
   },
   "outputs": [],
   "source": [
    "for row, sentence in enumerate(each_sentence):\n",
    "    for word in sentence.keys():\n",
    "        for k in idf.keys():\n",
    "            if word == k:\n",
    "                tf = sentence[word]\n",
    "#                 print([word, row],tf, idf[word])\n",
    "                results_df[word][row] = tf * idf[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "734e1e6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.340143Z",
     "start_time": "2023-06-25T11:14:25.323100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>я</th>\n",
       "      <th>он</th>\n",
       "      <th>только</th>\n",
       "      <th>ты</th>\n",
       "      <th>не</th>\n",
       "      <th>и</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>я и ты</th>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ты и я</th>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.30543</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.170275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>я, я и только я</th>\n",
       "      <td>0.133886</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183258</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.102165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>только не я</th>\n",
       "      <td>0.074381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.305430</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.536479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>он</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        я        он    только       ты        не         и\n",
       "я и ты           0.074381  0.000000  0.000000  0.30543  0.000000  0.170275\n",
       "ты и я           0.074381  0.000000  0.000000  0.30543  0.000000  0.170275\n",
       "я, я и только я  0.133886  0.000000  0.183258  0.00000  0.000000  0.102165\n",
       "только не я      0.074381  0.000000  0.305430  0.00000  0.536479  0.000000\n",
       "он               0.000000  1.609438  0.000000  0.00000  0.000000  0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 3 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "745bd58f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.470781Z",
     "start_time": "2023-06-25T11:14:25.343222Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac0a5471",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.564021Z",
     "start_time": "2023-06-25T11:14:25.472942Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/alexandradolidze/Desktop/compling/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "620f249f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.578397Z",
     "start_time": "2023-06-25T11:14:25.566075Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "\n",
    "y_train = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "68be819c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.589934Z",
     "start_time": "2023-06-25T11:14:25.581092Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Верблюдов-то за что? Дебилы, бл...\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Хохлы, это отдушина затюканого россиянина, мол...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Собаке - собачья смерть\\n</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Страницу обнови, дебил. Это тоже не оскорблени...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>тебя не убедил 6-страничный пдф в том, что Скр...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  toxic\n",
       "0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n",
       "1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n",
       "2                          Собаке - собачья смерть\\n    1.0\n",
       "3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n",
       "4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26eaa062",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:15:21.268191Z",
     "start_time": "2023-06-25T11:15:21.258898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', 'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', 'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', 'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда', 'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом', 'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех', 'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/alexandradolidze/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download(\"stopwords\")\n",
    "stopwords = stopwords.words('russian')\n",
    "\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "27b90bae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:22:00.645458Z",
     "start_time": "2023-06-25T11:22:00.641093Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer1 = CountVectorizer(lowercase = False, binary = True, stop_words = stopwords, max_df = 0.9, min_df = 5, max_features = 10000, ngram_range=(1,3))\n",
    "vectorizer2 = TfidfVectorizer(stop_words = stopwords, binary = True, max_df = 0.9, min_df = 5, max_features = 10000, ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a449c882",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:35:32.173515Z",
     "start_time": "2023-06-25T11:35:29.162415Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.81      0.85       970\n",
      "         1.0       0.67      0.80      0.73       472\n",
      "\n",
      "    accuracy                           0.81      1442\n",
      "   macro avg       0.78      0.80      0.79      1442\n",
      "weighted avg       0.82      0.81      0.81      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression \n",
    "X_train1 = vectorizer1.fit_transform(train.comment)\n",
    "X_test1 = vectorizer1.transform(test.comment) \n",
    "\n",
    "classifier1 = LogisticRegression(solver = 'liblinear', penalty = 'l2', class_weight = 'balanced')\n",
    "classifier1.fit(X_train1, y_train)\n",
    "\n",
    "y_preds1 = classifier1.predict(X_test1)\n",
    "\n",
    "print(classification_report(y_test, y_preds1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b0c7ff7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:29:11.565440Z",
     "start_time": "2023-06-25T11:29:07.105471Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.81      0.82       970\n",
      "         1.0       0.63      0.69      0.66       472\n",
      "\n",
      "    accuracy                           0.77      1442\n",
      "   macro avg       0.74      0.75      0.74      1442\n",
      "weighted avg       0.77      0.77      0.77      1442\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier\n",
    "X_train2 = vectorizer2.fit_transform(train.comment)\n",
    "X_test2 = vectorizer2.transform(test.comment) \n",
    "\n",
    "сlassifier2 = DecisionTreeClassifier(criterion = 'log_loss', splitter = 'random', max_depth = 1500, min_samples_split = 10, class_weight = 'balanced', random_state = 322)\n",
    "сlassifier2.fit(X_train2, y_train)\n",
    "\n",
    "y_preds2 = сlassifier2.predict(X_test2)\n",
    "\n",
    "print(classification_report(y_test, y_preds2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4b9289ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:35:44.513780Z",
     "start_time": "2023-06-25T11:35:44.503999Z"
    }
   },
   "outputs": [],
   "source": [
    "# индексы с самой высокой вероятностью в классе токсичных (toxic = 1.0)\n",
    "\n",
    "y_probas1 = classifier1.predict_proba(X_test1)\n",
    "y_probas2 = сlassifier2.predict_proba(X_test2)\n",
    "\n",
    "# np.argsort(y_probas1, axis=0)[:10][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4791eace",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:44:51.795907Z",
     "start_time": "2023-06-25T11:44:51.790900Z"
    }
   },
   "outputs": [],
   "source": [
    "toxic_texts = pd.DataFrame(columns = ['LogisticRegression', 'DecisionTreeClassifier'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1d4d205e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:51:32.068594Z",
     "start_time": "2023-06-25T11:51:32.054192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Пиздец у быдла с пикабу сначала горело от негров на нулевой, теперь от скримеров, куда я нахуй попал, ебаные животные это БЭ, ЭТО РАНДОМ СУЧАРА, ТАМ НЕ ДОЛЖНО БЫТЬ ПРАВИЛ, ПОШЕЛ НАХУЙ\\n',\n",
       "       'Да, Эстетам похуй . Когда ваш главэстет будит униженно на весь интернет опровергать свой пиздёж про старикашку - вам тоже похуй будет? Ты долбоёб, гоблядь, Маэстро если и сделает такое извенение , то в нём ещё сильнее обосрёт старикашку и хайпанёт на этом)) Можешь придумывать кликбэйтные заголовки и отправлять лакеям)) Величайший историк извеняется перед гоблинским подсосом)) Маэстро: По решению подзалупного суда косплеер не плагиатор, не бандит, не насильник, не педофил, слышите!? И сам пишет свои маняграфии)) Пусть до конца жизни судится, спляшем с Книгой Века на его могиле))',\n",
       "       'Стас, никому, кроме тебя и армии твоих подсосов(которые представляют собой типичный дегенеративный биомусор, ведущийся на любые скандалы-интриги), твои ролики нахуй не нужны. Серьёзно, ты сделал новости с целью показать, что такое говно может делать любой, а аудитория осталась на том же уровне, ведь людям извне ты не интересен. Да ещё и просит не подписываться, чтобы такую-то годноту ложкой хлебать подольше. Ты обосрался, стал посмешищем для абсолютно всех ютуберов, которые не являются полными ебланами. Тот же Хованский не ссыт тебе на ебало только потому, что ты вертишься с ним в одной компании, иногда даже лично пересекаетесь. Приятно было слышать, как он говорил, что отстреливался бы от таких, как ты, из огнестрела, стараясь забрать с собой побольше коммунистов, когда они придут его оаскулачиапть? Он открыто хуесосил людей и за меньшие грехи. Сложи 2 и 2, как он к тебе относится на самом деле. После чего ты сделал ещё более смешной ролик, где истеришь как побитая шлюха во время ПМС. Я ПОДЕБИЛ, А ЕСЛИ ВЫ НЕ ПОНЯЛИ ЭТОГО, ТО ВЫ ТУПЫЕ . Ты мог хотя бы сам его посмотреть перед заливом? Мне даже рофлить над тобой расхотелось, из смешного дегенерата, ты стал жалким дурачком. Это как смеятся над роликами, где контуженные ветераны пытаются ходить под клубную музыку. Над неполноценными смеятся плохо, даже стыдно стало. Я не утрирую. Просто посмотри на себя, Стас. Ну правда. Банишь людей в группе за лвйки и одно упоминание стрима. Ты делаешь всё, в чём самый отбитый и дегенеративный либераст обвиняет совок и сверкаешь разорванным очком. Никто тебя несправедливо не обсирал. Что на стриме по поводу дат, ну ты же сам проебался. На подкасте сообщил, что не будешь стримить. Если ты не был уверен, то зачем это говорить? А если был, почему не сообщил Маргиналу сразу же? Твоё слово в целом не стоит нихуя. Обещаешь не банить-куча удалённых комментов. Обещаешь стрим-не идёшь. Обещаешь что-то ещё, всегда проёбываешься, всё чаще на нарушение обещания тебе нужно в районе секунды-дня. Стоит ли удивлятся, что тебе за это прилетело? Когда то должно было. Ты сам срёшь себе в штаны, не злись, когда на это указывают пальцем.',\n",
       "       'Двач. Ну это пиздец, конечно. Раньше я его уважал, но теперь пошел он в пизду. На дваче такой зашквар сидеть и что самое смешное многие популярные конченные блогеры сидят на дваче, но я уж надеялся, что хотя бы Гуфен не такой, но раз он сидит на этой параше, то похуй.\\n',\n",
       "       'В Киеве на вокзале Мен було рок в 19, коли мене перший раз мав в зад хлопець рок в п д 30. Я тод перш рази став заходити на вокзал Ки в-Пасажирський в туалети - де були каб ни з д рками написи на ст нах. Так як досв ду ще не було н якого, то як знайомиться не уявляв. Сам перший природно не п дходив. А видивлявся на написи. дрочив св й член стоячи в каб нц . Хлопець був у сус дн й каб нц , в н побачив це, хитнув мен головою, запрошуючи п ти з ним. А так як н кого б льше в той момент не було, а був уже веч р, над на щось нше не було -все ж п шов за ним. У мене вже тод з явилася молофья - я вже спускав. Так як трохи ран ше ще не було, при дрочц робив це до при много стану - коли просто ставало дуже добре - але з хуя н чого не вид лялося. А до цього мен вже к лька раз в смоктали член хлопц мужики, я спускав м в рот, знав як це при мно. Ми прийшли б ля вокзалу кудись в кущ . В н розстебнув мен мотню, д став м й член став дрочити. А в той час нав ть це - коли хтось чужий рукою просто всього лише дрочив мен - було все одно дуже при мно. забирало. Бо коли тоб дрочать чужою рукою в дитинств - це вже щось: в д цього балд ш дуже. В н, ймов рно, здогадуючись, що перед ним зовс м новачок не намагався нав ть мен св й дати в руку: Так в н мене зав в , а пот м попросив повернутися: Я запитав нав що, справд не розум ючи нав що - а в н сказав треба так. я як теля повернувся п дкоряючись команд дорослого. В н приспустив мен штани, труси приставив до дерева у якого ми стояли, трохи нагнувши мене. А сам встав ззаду. По звуках я зрозум в, що в н розст ба соб свою мотню д ста св й член. В н притулився до мо поп сво м хуем, в д чого я здригнувся, але в н взяв мене за м й член знову став дрочити. А ншою рукою водити по стегнах з внутр шньо сторони. П д ймаючись в д кол н до поп - це посилювало кайф в д дрочк , я мл в, в н це теж в дчував, вже спок йно став тертися сво м хуем мен по поп . Пот м в н перестав дрочити мен , я почув як в н послинив св й член мою д рочку приставив мен св й член, в дсунув мене в д дерева трохи, пригнув мене почав засовували член в мене. Я стояв нагнувшись, упершись руками в дерево, н живий, н мертвий - перший раз в житт хлопець в мене засовував св й хуй! Я боявся - як все буде, що буде з мною, як це. Мен пощастило, звичайно, для першого разу, що у нього був маленький тонкий хуй. Тому н яких проблем у нього з всуванням його хуя в мою св жу попку не було. Оск льки мен не було боляче або непри мно я стояв не с паючись. Чекаючи як що буде дал :. В н засунув св й член весь в мене. т льки коли в н встромив його до к нця - було в дчуття що в н у щось уперся. Але не боляче зовс м. треба сказати чесно, що було при мно в дчувати, коли яйця його доторкнулися до мо попки, до д рочки, коли весь член був уже всередин не .. Це при мне в дчуття, коли умоглядно уявля ш що в тебе чийсь член засунуть: Це було мабуть нав ть при мн ше н ж все нше - в дчувати його яйця б ля очка. Коли весь член вже там. коли в н пот м став й бати мене, я намагався щоб част ше яйця його впиралися в попу мен , нав ть нод насаджувався сам глибше на його член, до упору. Але показувати що мен щось при мно тод здавалося ще не зручним - б льший час я просто стояв обхопивши дерево руками, а в н вставляв член в мене. Хоча особливого кайфу я ще тод не в дчував - було в дчуття - що просто в мене встромляв хлопець св й член ходив там. Так в н мав мене, продовжуючи одночасно весь цей час одн ю рукою дрочить мен - п дтримуючи в мен бажання: - ось в д цього мен було при мно. Природно. Це був його розрахунок. Я досить швидко в д дрочк чужою рукою спустив, в дразу з скочив з його члена. Але в дчув що у мене щось липкою ззаду на стегнах: Що щось тече по стегнах з очка. ось це мене засмутило сильно. вбило - я здогадався зрозум в що в н спустив в мене. Запитав, - Ти що ск нчив у мене? в н сказав - так. запитав мене - а ти що перший раз це робив? я мало не плачучи в д образи сказав - що так, перший раз: поставив йому дурне питання - нав що ти в мене спустив? Я не припускав цього, думав що в н просто посует ться в мене св й хуй все, а тут мен стало не по соб : було огидно, - особливо п сля того як сам пустив, - що на мен чужа гидота , як тод сприймав чужу малофю . Та тим б льше на сво му т л . Але справа була зроблена: хлопця 19 рок в видрали в дупу! спустили сперму йому в очко! В струнку, пружну, н жну попочку з н жною д рочкою, засунувши в не перший раз член! У перший момент було огидно в д того що щось липке, спочатку тепле, ст кало по стегнах, а пот м застигло так: (а так як не готувався до цього, то витерти було н чим:) Тод було прикро, не за те що ви бав, а що не попередивши, спустив в мене. Так як тод сперма сприймалася як щось мерзенне, тим б льше на соб . Пот м згадував про це вже з та мним насолодою, нав ть бажанням, щоб це повторилося: я поб г швидко з цього м сця, скор ше в д нього, а липка р дина на стегнах весь час нагадувала, що мене т льки що ви бли в жопу. Слава Укра н !',\n",
       "       'О, свиньи вздумали еще и пидорах перефорсить. Смiявсь. Вот и я думаю, что на мнение пидорашек всем плевать. А я считаю, что пидорахи должны покинуть политач.\\n',\n",
       "       'Западенские каклы в Польше - это чмо пиздец какое просто. Сам лично одному там в автобусе втащил. Его блядь приняв меня за поланда начала обкладывать русским матом за то что я их согнал в автобусе с первых мест за которые заплатил, типа я нихуя не понимаю. Сами поляки при этом в кайф стояли и смотрели как русачек щемит какла.\\n',\n",
       "       'БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. НЕПРОБИВАЕМАЯ ХОХЛИНА, СУКА. Какие-же хохлы дененераты, пиздец просто.\\n',\n",
       "       'залетуха плиз, если ты так любишь покой, то ты бы вспомнил лето и осень, когда даун на модере тер АБСОЛЮТНО все, а так ты просто даун который очередной раз разжигаешь срач и тебе похуй на реакшены, главное просто повыебываться и посрать.\\n',\n",
       "       'Какие же хохлы незалежные дегенераты, пиздец просто.\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Самые токсичные тексты у первого классификатора\n",
    "toxic_texts['LogisticRegression'] = test.loc[np.argsort(y_probas1, axis=0)[:10][:,0],'comment'].values\n",
    "test.loc[np.argsort(y_probas1, axis=0)[:10][:,0],'comment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "07872444",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:51:53.319110Z",
     "start_time": "2023-06-25T11:51:53.309654Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Сука тупой дегенарт. Вот на эти видео. Съеби уже к своему старому куколду в жж, жухлые сморчки друг-другу теребить.\\n',\n",
       "       'Верните мне нормальную советскую медицину, я жить хочу.\\n',\n",
       "       'Кредитнулся и взял телефон Samsung WiTu Omnia. Поставил цифровой пароль и не прошло и месяца как телефон перестал узнавать пароль. Звонил в техподдержку Samsung ,а я и слово не успел сказать мне говорят ниипёт это не гарантийный случай п...уй в сервисный центр Samsung. В общем разблокировали мне его за 1000 причём попросили подписать бумагу если чо то притензий не имею. Из-за всего этого у меня остался какой-то неприятный осадочек. С тех пор телефоны и технику этой компании обходу стороной. Через 10 лет решил купить себе iPhone 5s чтобы узнать как это быть владельцем яблофона. Когда возникла проблема с телефоном я позвонил в поддержку Apple и мне там охотно помогли. С тех пор при всех минусах iPhone я более лоялен к этой технике. Знаю что отдав деньги как за 2 Samsunga меня не пошлют нах.\\n',\n",
       "       'Могут ли они пережить атомной взрыв? Если состав 1 окажется не в эпицентре, а на некотором отдалении то точно выдержит. Значит надо прицельно ебануть, делов то. И похуй там броня не броня.\\n',\n",
       "       'почему? Логика следующая - в фокусе центр,а чем дальше от зрителя и чем ближе к зрителю,то расфокус увеличивается\\n',\n",
       "       'Я просто общаюсь Пидораха пидораха Скотоублюдии пидорашки народ такой дранный Я просто общаюсь HOHLYATUS VULGARIS\\n',\n",
       "       'Из обсуждения в интернете чей Крым, ничего не решится, просто очередной диванный срач, зачем это? Тут я захожу про бабулек мошеников в банке в сговоре с сотовыми операторами читать, а вы блять со своей политикой, мне пох чей Крым! Это только Крымчан волнует, мне от того что Крым Украинский или России не жарко и не холодно.\\n',\n",
       "       'Как подробно он о себе рассказал все-таки.\\n',\n",
       "       'Русская кореец (на второй фотке мамка, да)\\n',\n",
       "       'А почему ты упустил вот это Ты не упустил. Молодец.\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Самые токсичные тексты у второго классификатора\n",
    "toxic_texts['DecisionTreeClassifier'] = test.loc[np.argsort(y_probas2, axis=0)[:10][:,0],'comment'].values\n",
    "test.loc[np.argsort(y_probas2, axis=0)[:10][:,0],'comment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "8301e318",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:44:56.222302Z",
     "start_time": "2023-06-25T11:44:56.212475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Пиздец у быдла с пикабу сначала горело от негр...</td>\n",
       "      <td>Сука тупой дегенарт. Вот на эти видео. Съеби у...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Да, Эстетам похуй . Когда ваш главэстет будит ...</td>\n",
       "      <td>Верните мне нормальную советскую медицину, я ж...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Стас, никому, кроме тебя и армии твоих подсосо...</td>\n",
       "      <td>Кредитнулся и взял телефон Samsung WiTu Omnia....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Двач. Ну это пиздец, конечно. Раньше я его ува...</td>\n",
       "      <td>Могут ли они пережить атомной взрыв? Если сост...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>В Киеве на вокзале Мен було рок в 19, коли мен...</td>\n",
       "      <td>почему? Логика следующая - в фокусе центр,а че...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>О, свиньи вздумали еще и пидорах перефорсить. ...</td>\n",
       "      <td>Я просто общаюсь Пидораха пидораха Скотоублюди...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Западенские каклы в Польше - это чмо пиздец ка...</td>\n",
       "      <td>Из обсуждения в интернете чей Крым, ничего не ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. ...</td>\n",
       "      <td>Как подробно он о себе рассказал все-таки.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>залетуха плиз, если ты так любишь покой, то ты...</td>\n",
       "      <td>Русская кореец (на второй фотке мамка, да)\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Какие же хохлы незалежные дегенераты, пиздец п...</td>\n",
       "      <td>А почему ты упустил вот это Ты не упустил. Мол...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  LogisticRegression  \\\n",
       "0  Пиздец у быдла с пикабу сначала горело от негр...   \n",
       "1  Да, Эстетам похуй . Когда ваш главэстет будит ...   \n",
       "2  Стас, никому, кроме тебя и армии твоих подсосо...   \n",
       "3  Двач. Ну это пиздец, конечно. Раньше я его ува...   \n",
       "4  В Киеве на вокзале Мен було рок в 19, коли мен...   \n",
       "5  О, свиньи вздумали еще и пидорах перефорсить. ...   \n",
       "6  Западенские каклы в Польше - это чмо пиздец ка...   \n",
       "7  БЕЛАРУСЬ, БЛЯТЬ, БЕЛАРУСЬ. СПИДОРСВИН, БЛЯТЬ. ...   \n",
       "8  залетуха плиз, если ты так любишь покой, то ты...   \n",
       "9  Какие же хохлы незалежные дегенераты, пиздец п...   \n",
       "\n",
       "                              DecisionTreeClassifier  \n",
       "0  Сука тупой дегенарт. Вот на эти видео. Съеби у...  \n",
       "1  Верните мне нормальную советскую медицину, я ж...  \n",
       "2  Кредитнулся и взял телефон Samsung WiTu Omnia....  \n",
       "3  Могут ли они пережить атомной взрыв? Если сост...  \n",
       "4  почему? Логика следующая - в фокусе центр,а че...  \n",
       "5  Я просто общаюсь Пидораха пидораха Скотоублюди...  \n",
       "6  Из обсуждения в интернете чей Крым, ничего не ...  \n",
       "7       Как подробно он о себе рассказал все-таки.\\n  \n",
       "8       Русская кореец (на второй фотке мамка, да)\\n  \n",
       "9  А почему ты упустил вот это Ты не упустил. Мол...  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9a545a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:47:10.155334Z",
     "start_time": "2023-06-25T11:47:10.122001Z"
    }
   },
   "source": [
    "Как-то они совершенно не совпадают.\n",
    "\n",
    "Видно, что дерево решений обозначило токсичными совсем не (или практически не) токсичные высказываний (например, №1-4), которые содержат ненормативную лексику, однако она явно используется с целью усилить эмоцию, передаваемую автором, а не оскорбить оппонента. \n",
    "\n",
    "В то же время классификатор на основе логистической регрессии показывает всю силу ненависти пользователей двача друг к другу и к самим себе. Интересно, что как токсичный был корректно классифицирован текст на украинском языке, который вероятно попал в датасет по ошибке при разметке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## *Задание 4 (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов LogisticRegression и Random Forest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90311fac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:25.994079Z",
     "start_time": "2023-06-25T11:14:25.994064Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "995197ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:57:47.719936Z",
     "start_time": "2023-06-25T11:57:47.403455Z"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('/Users/alexandradolidze/Desktop/compling/labeled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "e03c3585",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:58:01.355933Z",
     "start_time": "2023-06-25T11:58:01.234150Z"
    }
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.1, shuffle=True)\n",
    "train.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)\n",
    "\n",
    "y_train = train.toxic.values\n",
    "y_test = test.toxic.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "81f86878",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T12:00:05.625832Z",
     "start_time": "2023-06-25T12:00:03.005549Z"
    }
   },
   "outputs": [],
   "source": [
    "# буду работать с CountVectorizer с гиперпараметрами как в предыдудщем задании\n",
    "vectorizer = CountVectorizer(lowercase = False, stop_words = stopwords, max_df = 0.9, min_df = 5, max_features = 10000, ngram_range=(1,3))\n",
    "\n",
    "X_train = vectorizer.fit_transform(train.comment)\n",
    "X_test = vectorizer.transform(test.comment) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "15af4e1f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T12:22:20.008493Z",
     "start_time": "2023-06-25T12:22:19.669378Z"
    }
   },
   "outputs": [],
   "source": [
    "сlassifier1 = LogisticRegression()\n",
    "сlassifier1.fit(X_train, y_train)\n",
    "\n",
    "y_preds1 = сlassifier1.predict(X_test)\n",
    "\n",
    "coeffs1 = сlassifier1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "651a9ac8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T12:22:32.558035Z",
     "start_time": "2023-06-25T12:22:20.172666Z"
    }
   },
   "outputs": [],
   "source": [
    "сlassifier2 = RandomForestClassifier(random_state = 322)\n",
    "сlassifier2.fit(X_train, y_train)\n",
    "\n",
    "y_preds2 = сlassifier2.predict(X_test)\n",
    "\n",
    "coeffs2 = сlassifier2.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b1f7db02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T12:22:53.539596Z",
     "start_time": "2023-06-25T12:22:53.511439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые токсичные слова по логистической регрессии: ['сука' 'сжечь' 'дебил' 'хохлы' 'хохлов']\n",
      "Самые токсичные слова по случайному лесу: ['нахуй' 'хохлы' 'хохлов' 'тебе' 'Ты']\n"
     ]
    }
   ],
   "source": [
    "np.argsort(coeffs1)[-10:]\n",
    "\n",
    "print(f'Самые токсичные слова по логистической регрессии: {vectorizer.get_feature_names_out()[np.argsort(coeffs1)[0][-5:]]}')\n",
    "print(f'Самые токсичные слова по случайному лесу: {vectorizer.get_feature_names_out()[np.argsort(coeffs2)[-5:]]}')\n",
    "\n",
    "\n",
    "# vectorizer.get_feature_names_out()[np.argsort(coeffs1)[10:]]\n",
    "\n",
    "#test.loc[np.argsort(y_probas1, axis=0)[:10][:,0],'comment'].values\n",
    "#np.argsort(y_probas1, axis=0)[:10][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "98a6313a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T12:19:48.804237Z",
     "start_time": "2023-06-25T12:19:48.798098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2773, 1919, 4002, 8000,  673, 7723, 4723, 7164, 7721,  998])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(coeffs2)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b6d992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
